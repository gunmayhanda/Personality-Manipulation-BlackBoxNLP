\section{Introduction}

Personality control in LLMs is increasingly common, yet capability trade-offs remain poorly quantified. Personality modeling evolved from rule-based approaches \citep{mairesse-walker-2007-personage} to neural architectures, with LLMs exhibiting consistent personality behaviors when conditioned \citep{jiang-etal-2023-personallm, huang-etal-2023-chatgpt-personality}. Big Five emerged as the dominant framework due to empirical validation \citep{costa-mccrae-1992-big5}, with studies showing LLMs can be assessed using personality questionnaires \citep{serapio-garcia-etal-2023-personality-traits-llms}. Mechanistic interpretability advances enable direct model manipulation through steering vectors \citep{turner-etal-2023-activation-steering} and representation engineering \citep{li-etal-2023-representation-engineering}. LoRA \citep{hu-etal-2022-lora} has been applied to personality conditioning \citep{zhang-etal-2023-peft-personality}. Evaluation frameworks like BBQ \citep{parrish-etal-2022-bbq}, MMLU \citep{hendrycks-etal-2021-mmlu}, and GAIA \citep{mialon-etal-2023-gaia} enable bias and capability assessment. However, prior work lacks consistent cross-method comparisons across ICL, PEFT, and activation steering. From an interpretability perspective, personality manipulation serves as an experimental probe to understand behavioral trait encoding. We systematically study three Big Five manipulation approaches—ICL, PEFT (LoRA), and activation steering—using relative change (\(\Delta\)) analysis within each method's baseline and independent alignment validation. Our contributions: (1) unified \(\Delta\)-based evaluation revealing method-specific encoding mechanisms; (2) cross-method analysis linking capability changes to alignment strength; (3) mechanistic insights into personality control pathways. \textbf{Detailed related work is in Appendix~\ref{app:background}.}