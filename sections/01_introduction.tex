\section{Introduction}

Personality control in LLMs is increasingly common, yet capability trade-offs remain poorly quantified. Prior work spans in-context learning (ICL), parameter-efficient fine-tuning (PEFT), and activation steering, but lacks consistent cross-method comparisons. From an interpretability perspective, personality manipulation serves as an experimental probe to understand behavioral trait encoding. We systematically study three Big Five manipulation approaches—ICL, PEFT (LoRA), and activation steering—using relative change (\(\Delta\)) analysis within each method's baseline and independent alignment validation. Our contributions: (1) unified \(\Delta\)-based evaluation revealing method-specific encoding mechanisms; (2) cross-method analysis linking capability changes to alignment strength; (3) mechanistic insights into personality control pathways.