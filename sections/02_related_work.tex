\section{Related Work}

Our work builds on personality modeling, model steering, and interpretability methods.

\textbf{Personality in LLMs:} Personality modeling evolved from rule-based approaches \citep{mairesse-walker-2007-personage} to neural architectures. LLMs exhibit consistent personality behaviors when conditioned \citep{jiang-etal-2023-personallm, huang-etal-2023-chatgpt-personality}. Big Five emerged as the dominant framework due to empirical validation \citep{costa-mccrae-1992-big5}, with studies showing LLMs can be assessed using personality questionnaires \citep{serapio-garcia-etal-2023-personality-traits-llms}.

\textbf{Model Control:} Mechanistic interpretability advances enable direct model representation manipulation. \citet{turner-etal-2023-activation-steering} introduced steering vectors from activation differences, while \citet{li-etal-2023-representation-engineering} formalized representation engineering for model control. LoRA \citep{hu-etal-2022-lora} has been applied to personality conditioning \citep{zhang-etal-2023-peft-personality}, offering alternatives to in-context learning.

\textbf{Evaluation:} Personality manipulation evaluation requires systematic frameworks. BBQ \citep{parrish-etal-2022-bbq}, MMLU \citep{hendrycks-etal-2021-mmlu}, and GAIA \citep{mialon-etal-2023-gaia} enable bias and capability assessment. Our work extends these to personality manipulation contexts.

\textbf{\noindent Detailed related work is in Appendix~\ref{app:background}.}