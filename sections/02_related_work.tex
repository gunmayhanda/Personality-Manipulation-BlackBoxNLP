\section{Related Work}

Our work builds on three key areas: personality modeling in LLMs, model steering techniques, and interpretability methods for understanding behavioral control mechanisms.

\textbf{Personality in LLMs:} The computational modeling of personality has evolved from early rule-based approaches \citep{mairesse-walker-2007-personage} to neural architectures. Recent work has shown that LLMs can exhibit consistent personality-like behaviors when properly conditioned \citep{jiang-etal-2023-personallm, huang-etal-2023-chatgpt-personality}. The Big Five personality model has emerged as the dominant framework due to its empirical validation \citep{costa-mccrae-1992-big5}, with several studies demonstrating that LLMs can be assessed using established personality questionnaires \citep{serapio-garcia-etal-2023-personality-traits-llms}.

\textbf{Model Control and Steering:} Recent advances in mechanistic interpretability have enabled direct manipulation of model representations. \citet{turner-etal-2023-activation-steering} introduced steering vectors derived from activation differences, while \citet{li-etal-2023-representation-engineering} formalized representation engineering as a general framework for model control. Parameter-efficient methods like LoRA \citep{hu-etal-2022-lora} have been applied to personality conditioning \citep{zhang-etal-2023-peft-personality}, offering alternatives to in-context learning approaches.

\textbf{Interpretability and Evaluation:} Understanding how personality manipulation affects model behavior requires sophisticated evaluation frameworks. Standardized benchmarks like BBQ \citep{parrish-etal-2022-bbq}, MMLU \citep{hendrycks-etal-2021-mmlu}, and GAIA \citep{mialon-etal-2023-gaia} enable systematic assessment of bias and capability changes. Our work extends these evaluation approaches to personality manipulation contexts.

\noindent Detailed related work is provided in Appendix~\ref{app:background}.