Plain Text Conversion
Gemma_2 Prompting MMLU:
* metric, Baseline, extraversion, agreeableness, neuroticism, openness, conscientiousness
* Accuracy_Avg: 0.5057, 0.5057, 0.5114, 0.4971, 0.5171, 0.5114
* Accuracy_abstract_algebra: 0.22, 0.32, 0.24, 0.24, 0.36, 0.2
* Accuracy_college_physics: 0.38, 0.44, 0.4, 0.4, 0.42, 0.4
* Accuracy_high_school_psychology: 0.78, 0.78, 0.84, 0.82, 0.84, 0.88
* Accuracy_high_school_us_history: 0.64, 0.6, 0.52, 0.64, 0.6, 0.56
* Accuracy_logical_fallacies: 0.74, 0.68, 0.8, 0.68, 0.78, 0.72
* Accuracy_moral_scenarios: 0.28, 0.32, 0.34, 0.26, 0.26, 0.32
* Accuracy_professional_law: 0.5, 0.4, 0.44, 0.44, 0.36, 0.5
________________


FINAL RESULTS FOR: raw_outputs_gemma2_MMLU_steering.jsonl
* Model/Metric, Baseline, extraversion, agreeableness, neuroticism, openness, conscientiousness
* Accuracy_Avg: 0.5000, 0.3571, 0.0514, 0.2457, 0.4743, 0.0714
* Accuracy_abstract_algebra: 0.1600, 0.2200, 0.0200, 0.1200, 0.3400, 0.0400
* Accuracy_college_physics: 0.4000, 0.2600, 0.0200, 0.1200, 0.3400, 0.0200
* Accuracy_high_school_psychology: 0.8400, 0.6600, 0.1200, 0.4200, 0.7400, 0.1800
* Accuracy_high_school_us_history: 0.6400, 0.4600, 0.0600, 0.2800, 0.5800, 0.0600
* Accuracy_logical_fallacies: 0.7000, 0.4400, 0.0200, 0.4000, 0.7200, 0.0800
* Accuracy_moral_scenarios: 0.3200, 0.2800, 0.0200, 0.2400, 0.2800, 0.0200
* Accuracy_professional_law: 0.4400, 0.1800, 0.1000, 0.1400, 0.3200, 0.1000
________________


Gemma_2 PEFT MMLU:
* benchmark, metric, Baseline, extraversion, agreeableness, neuroticism, openness, conscientiousness
* MMLU, Accuracy_Avg: 0.1828, 0.1828, 0.0542, 0.0371, 0.0942, 0.1885
* MMLU, Accuracy_abstract_algebra: 0.02, 0.02, 0.0, 0.06, 0.16, 0.1
* MMLU, Accuracy_college_physics: 0.16, 0.26, 0.06, 0.08, 0.1, 0.24
* MMLU, Accuracy_high_school_psychology: 0.22, 0.22, 0.18, 0.04, 0.1, 0.3
* MMLU, Accuracy_high_school_us_history: 0.3, 0.2, 0.02, 0.04, 0.08, 0.16
* MMLU, Accuracy_logical_fallacies: 0.28, 0.24, 0.02, 0.02, 0.06, 0.26
* MMLU, Accuracy_moral_scenarios: 0.1, 0.14, 0.02, 0.0, 0.02, 0.14
* MMLU, Accuracy_professional_law: 0.2, 0.2, 0.08, 0.02, 0.14, 0.12
________________


Summarized Results
This document presents MMLU benchmark results for the Gemma-2 model, modified to exhibit Big Five personality traits using three different methods: prompting, activation steering, and PEFT.
1. Prompting:
   * The baseline model achieved an average accuracy of 50.6%.
   * Prompting the model with personality traits caused only minor fluctuations in performance, with average accuracy ranging from 49.7% (neuroticism) to 51.7% (openness). This method had a minimal impact on overall capability.
2. 3. Activation Steering:
   * The baseline model had an average accuracy of 50.0%.
   * Steering had a severe and mostly negative impact on performance.
   * Accuracy dropped dramatically for most traits, especially agreeableness (5.1%) and conscientiousness (7.1%).
4. 5. PEFT (Parameter-Efficient Fine-Tuning):
   * This method led to a catastrophic performance collapse.
   * The baseline MMLU average accuracy plummeted to 18.3%.
   * Performance with personality traits was even worse, with neuroticism-tuned models scoring only 3.7% and agreeableness models scoring 5.4%.
6. ________________


Gemma_2 Steering Alignment Validation Details
Statistical validation was performed to confirm if the steering vectors effectively aligned the model's behavior with the target personality traits.
1. Initial Validation Report
The initial report tested all five personality traits.
Trait
	Layer
	Strength
	Baseline Acc (95% CI)
	Steered Acc (95% CI)
	Cleanliness (95% CI)
	P-Value
	Significant? (p < 0.05)
	Extraversion
	15
	200.0
	17.1% (15.6% - 18.5%)
	81.2% (78.7% - 83.8%)
	98.5% (97.7% - 99.4%)
	0.0000
	True
	Agreeableness
	10
	100.0
	1.0% (0.4% - 1.7%)
	44.6% (43.4% - 45.8%)
	99.4% (98.8% - 100.0%)
	0.0000
	True
	Neuroticism
	15
	200.0
	2.3% (1.1% - 3.5%)
	51.9% (49.8% - 54.0%)
	99.8% (99.5% - 100.1%)
	0.0000
	True
	Openness
	20
	50.0
	65.0% (62.4% - 67.6%)
	66.5% (65.1% - 67.8%)
	99.4% (99.4% - 99.4%)
	1.0000
	False
	Conscientiousness
	15
	250.0
	15.6% (13.5% - 17.7%)
	44.2% (40.5% - 47.9%)
	98.3% (97.5% - 99.2%)
	0.0000
	True
	Conclusion: The steering method was statistically significant for Extraversion, Agreeableness, Neuroticism, and Conscientiousness. However, it failed for Openness, with a P-value of 1.0000 indicating no significant change between baseline and steered accuracy.
2. Revised Methodology for Openness ("Purified Openness V3")
A second attempt was made to steer for Openness using a fixed, updated methodology where we added the original vector to a vector of the diff between mean activations and mean activations for all of the other traits. We ran this bottom one 10 times
Trait
	Layer
	Strength
	Baseline Acc (95% CI)
	Steered Acc (95% CI)
	Cleanliness (95% CI)
	P-Value
	Significant? (p < 0.05)
	Openness
	15
	110.0
	64.5% (62.7% - 66.3%)
	74.2% (72.5% - 75.9%)
	99.8% (99.5% - 100.0%)
	0.2284
	False
	Conclusion: